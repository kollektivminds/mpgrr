{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MAPRR Textual Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    "import logging\n",
    "from threading import *\n",
    "import concurrent\n",
    "import random\n",
    "import pickle\n",
    "import json\n",
    "import pandas as pd \n",
    "import re\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "from natasha import (\n",
    "    Segmenter, \n",
    "    MorphVocab, \n",
    "    NewsEmbedding, \n",
    "    NewsMorphTagger, \n",
    "    NewsSyntaxParser, \n",
    "    NewsNERTagger, \n",
    "    PER, \n",
    "    NamesExtractor, \n",
    "    Doc)\n",
    "from razdel import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='maprr_out.log', encoding='utf-8', format='%(asctime)s %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_cols = ['w_id', 'title_ru', 'text', 'title_en', '1st_line', 'author', 'comp_date', 'comp_loc', 'pub_src', '1st_pub', 'pub_year', 'pub_loc']\n",
    "a_cols = ['name', 'birth', 'death', 'a_type', 'sex', 'occs', 'fam_soc_str', 'lit_affil', 'pol_affil', 'corp_type', 'corp_affil']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = 'https://maprr.iath.virginia.edu/'\n",
    "max_threads = 3\n",
    "tables = {\n",
    "    'agents/': 332, \n",
    "    'works/': 655, \n",
    "    'place_based_concepts/': 316, \n",
    "    'locations/': 380, \n",
    "    'multivalent_markers/': 449\n",
    "}\n",
    "tables = {\n",
    "    'agents/': 3,\n",
    "    'works/': 6,\n",
    "    'place_based_concepts/': 3, \n",
    "    'locations/': 3,\n",
    "    'multivalent_markers/': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "allURLs = [domain+item[0]+str(i) for item in tables.items() for i in range(1, item[1]+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "urls_to_visit = [] \n",
    "for t, i in list(tables.items())[:2]: \n",
    "    for j in range(0,i+1): \n",
    "        urls_to_visit.append(domain+t+str(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class maprr: \n",
    "    \n",
    "    def __init__(self): \n",
    "        self.Wsoup = {} \n",
    "        self.Asoup = {}\n",
    "        self.Ws = {}\n",
    "        self.As = {}\n",
    "    \n",
    "    def get_htmlA(self): \n",
    "        \"\"\"This function uses the list of Agent IDs from the tables dict above\n",
    "        and the grabs it using requests before putting the html reponse in Asoup\"\"\"\n",
    "        \n",
    "        # initialize list of pages that don't return 200\n",
    "        aberrantAs = []\n",
    "        # go through list of Agents from 1 to the number defined in tables\n",
    "        for i in range(1, (list(tables.values())[0]+1)):\n",
    "        #for i in range(1, 11):\n",
    "            # make url\n",
    "            url = domain+list(tables.keys())[0]+str(i) \n",
    "            # initialize connection to url \n",
    "            with requests.get(url, verify=False) as r: \n",
    "                # log status code \n",
    "                logging.info(f\"A{i} status code: {r.status_code}\")\n",
    "                # if connection is successful\n",
    "                if r.status_code == 200: \n",
    "                    # make soup from html\n",
    "                    s = BeautifulSoup(r.content, 'html.parser') \n",
    "                    # add to list of A soups\n",
    "                    self.Asoup.update({i:s})\n",
    "                else: \n",
    "                    # if connection is not successful, add to list\n",
    "                    aberrantAs.append((i, r.status_code))\n",
    "                    pass\n",
    "                # wait a hot second or the server gets >:( \n",
    "                time.sleep(.1)\n",
    "        # report list of A errors if there is one (there always is)\n",
    "        if len(aberrantAs) > 0: \n",
    "            print(f\"Aberrant agent pages are #s {aberrantAs}\")\n",
    "        else: \n",
    "            print(f\"There were no aberrant agent pages!\")\n",
    "\n",
    "    def get_htmlW(self): \n",
    "        \"\"\"This function uses the list of Work IDs from the tables dict above\n",
    "        and the grabs it using requests before putting the html reponse in Wsoup\"\"\"\n",
    "        \n",
    "        # initialize list of pages that don't return 200\n",
    "        aberrantWs = []\n",
    "        # go through list of Words from 1 to the number defined in tables\n",
    "        for i in range(1, (list(tables.values())[1]+1)):\n",
    "        #for i in range(1, 11):\n",
    "            # make url\n",
    "            url = domain+list(tables.keys())[1]+str(i)\n",
    "            # initialize connection to url \n",
    "            with requests.get(url, verify=False) as r: \n",
    "                # log status code\n",
    "                logging.info(f\"W{i} status code: {r.status_code}\")\n",
    "                # if connection is successful\n",
    "                if r.status_code == 200: \n",
    "                    # make soup from html\n",
    "                    s = BeautifulSoup(r.content, 'html.parser')\n",
    "                    # add to list of A soups\n",
    "                    self.Wsoup.update({i:s})\n",
    "                else: \n",
    "                    # if connection is not successful, add to list\n",
    "                    aberrantWs.append((i, r.status_code))\n",
    "                    pass\n",
    "                # wait a hot second or the server gets >:( \n",
    "                time.sleep(.1)\n",
    "        # report list of A errors if there is one (there always is)\n",
    "        if len(aberrantWs) > 0: \n",
    "            print(f\"Aberrant work pages are #s {aberrantWs}\")\n",
    "        else: \n",
    "            print(f\"There were no aberrant work pages!\")\n",
    "\n",
    "    def parseWs(self, html): \n",
    "        \"\"\"This function retrieves Work info from the HTML provided\"\"\"\n",
    "        \n",
    "        # extract things we will need\n",
    "        content = html.find('div', {'class':'col-md-9 fixed-height'})\n",
    "        # try to locate author text of Work\n",
    "        try: \n",
    "            author = content.div.h3.text\n",
    "        except: \n",
    "            author = \"unknown\"\n",
    "        # try to locate title text of Work\n",
    "        try: \n",
    "            title = content.div.h4.text\n",
    "        except: \n",
    "            title = \"untitled\"\n",
    "        # try for both stanza and para text because they return [] \n",
    "        stanza_text = content.find_all('p',{'class':'stanza'})\n",
    "        prose_text = content.find_all('p',{'class':'text'})\n",
    "        # decide which text to use based on length \n",
    "        if len(prose_text) > len(stanza_text): \n",
    "            text = prose_text\n",
    "            genre = 'prose'\n",
    "        else: \n",
    "            text = stanza_text\n",
    "            genre = 'poetry'\n",
    "        # get actual text \n",
    "        Wtext = [x.text.replace('\\n','').strip() for x in text]\n",
    "        # make list of keys of Work types\n",
    "        typeKeys = [x.text[:-1] for x in html.find('div', {'class':'card-body'}).find_all('h4')]\n",
    "        # make list of values of Work types \n",
    "        typeVals = [x.text for x in html.find('div', {'class':'card-body'}).find_all('p')]\n",
    "        # make dictionary of keys:values from above\n",
    "        typeDict = dict(zip(typeKeys, typeVals))\n",
    "        # initialize sub dictionary of Work\n",
    "        Wdict = {'title': title, \n",
    "                   'genre': genre,\n",
    "                   'text': Wtext} \n",
    "        # add type keys and values to complete sub dictionary of Work\n",
    "        Wdict.update(typeDict) \n",
    "        # return Work dict to be made into a DataFrame row\n",
    "        return Wdict\n",
    "\n",
    "    def parseAs(self, html): \n",
    "        \"\"\"This function retrieves Agent info from the HTML provided\"\"\"\n",
    "        \n",
    "        # get Agent's name\n",
    "        name = html.find('div', {'class': 'card scrollable'}).h2.text \n",
    "        # get Agent's birth- and deathdates \n",
    "        bdate, ddate = html.find('div', {'class': 'card scrollable'}).span.text.split(' - ') \n",
    "        # initialize dictionary of Agent\n",
    "        Adict = {'name': name, 'birth': bdate, 'death': ddate}\n",
    "        # make list of type keys\n",
    "        typeKeys = [x.h4.text.lower().replace(' ','_') for x in html.find_all('div', {'class': 'col-md-4'})]\n",
    "        # initialize list of type values\n",
    "        typeVals = []\n",
    "        # add type values to list if found or default to 'unknown' (though some real values are also 'unknown')\n",
    "        for typ in html.find_all('div', {'class': 'col-md-4'}): \n",
    "            try: \n",
    "                typeVals.append(typ.p or typ.div.span.text)\n",
    "            except: \n",
    "                typeVals.append(\"unknown\")\n",
    "        # for some reason keys are at different levels and require '.text.' attribute but of course some don't\n",
    "        typeVals = [x.text if not isinstance(x, str) else x for x in typeVals]\n",
    "        # make dictionary of keys:values from above\n",
    "        typeDict = dict(zip(typeKeys, typeVals))\n",
    "        # add type keys and values to complete sub dictionary of Work\n",
    "        Adict.update(typeDict) \n",
    "        # return Agent dict to be made into a DataFrame row \n",
    "        return Adict\n",
    "    \n",
    "    def get_single(self, cat, id_num): \n",
    "        \"\"\"This function combines the functions above and returns the DataFrame row\"\"\" \n",
    "        \n",
    "        # make url from parameters and initialize request \n",
    "        with requests.get(domain+cat+'s/'+str(id_num), verify=False) as r: \n",
    "            # double check the URL is correct\n",
    "            print(r.url)\n",
    "            # check status code\n",
    "            print(f\"{cat+str(id_num)} status code: {r.status_code}\")\n",
    "            # if connection is successful\n",
    "            if r.status_code == 200: \n",
    "                # make soup from html content \n",
    "                s = BeautifulSoup(r.content, 'html.parser')\n",
    "                # sort by FOO type \n",
    "                if cat.lower() == 'work': \n",
    "                    # make dictionary if Work with parseWs function\n",
    "                    SubDict = {id_num:self.parseWs(s)}\n",
    "                elif cat.lower() == 'agent': \n",
    "                    # make dictionary if Agent with parseAs function\n",
    "                    SubDict = {id_num:self.parseAs(s)} \n",
    "                else: \n",
    "                    print(\"You need a category: 'work' or 'agent'...\") \n",
    "                # make DataFrame row from dictionary\n",
    "                singleDf = pd.DataFrame.from_dict(newSubDict, orient='index')\n",
    "                # return DataFrame row\n",
    "                return singleDf\n",
    "            # return status code if connection is unsuccessful\n",
    "            else: \n",
    "                print(f\"Error: {r.status_code}\") \n",
    "                \n",
    "    def save_obj(self, obj, name):\n",
    "        with open(name + '.pkl', 'wb+') as f:\n",
    "            pickle.dump(obj, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    def load_obj(self, name):\n",
    "        with open(name + '.pkl', 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "\n",
    "    def run(self): \n",
    "        \"\"\"This function runs retrieval and parsing using the functions above, creates DataFrames, and persists them (JSON)\"\"\"\n",
    "        \n",
    "        logging.info(f\"Getting As and Ws\")\n",
    "        print(f\"Getting As\")\n",
    "        # get starting time for A retrieval\n",
    "        at1 = time.time()\n",
    "        # retrieve As\n",
    "        self.get_htmlA() \n",
    "        # get finishing time for A retrieval\n",
    "        at2 = time.time()\n",
    "        # display run times for A retrieval \n",
    "        logging.info(f\"Got As in {round((at2-at1), 3)} sec ({round(((at2-at1)/list(tables.values())[0]), 5)} sec/ea.)\")\n",
    "        \n",
    "        print(f\"Getting Ws\")\n",
    "        # get starting time for W retrieval\n",
    "        wt1 = time.time()\n",
    "        # retrieve As\n",
    "        self.get_htmlW() \n",
    "        # get finishing time for W retrieval\n",
    "        wt2 = time.time()\n",
    "        # display run times for W retrieval \n",
    "        print(f\"Got Ws in {round((wt2-wt1), 3)} sec ({round(((wt2-wt1)/list(tables.values())[1]), 5)} sec/ea.)\")\n",
    "        logging.info(f\"Got Ws in {round((wt2-wt1), 3)} sec ({round(((wt2-wt1)/list(tables.values())[1]), 5)} sec/ea.)\")\n",
    "        \n",
    "        logging.info(f\"Done getting As and Ws\")\n",
    "        \n",
    "        self.save_obj(self.Asoup, 'Asoup')\n",
    "        self.save_obj(self.Wsoup, 'Wsoup')\n",
    "        \n",
    "        logging.info(f\"Parsing As and Ws\")\n",
    "        \n",
    "        logging.info(f\"Parsing As\")\n",
    "        print(f\"Parsing As\")\n",
    "        # get starting time for A parsing\n",
    "        pa1 = time.time()\n",
    "        # parse Agent HTML instances\n",
    "        self.As = {k: self.parseAs(v) for k, v in self.Asoup.items()}\n",
    "        # get finishing time for A parsing\n",
    "        pa2 = time.time()\n",
    "        # display run times for A parsing \n",
    "        logging.info(f\"Parsed As in {round((pa2-pa1), 3)} sec ({round((pa2-pa1)/len(list(self.Asoup.items())), 5)} sec/ea.)\")\n",
    "        \n",
    "        print(f\"Parsing Ws\")\n",
    "        # get starting time for W parsing\n",
    "        pw1 = time.time()\n",
    "        # parse Work HTML instances \n",
    "        self.Ws = {k: self.parseWs(v) for k, v in self.Wsoup.items()}\n",
    "        # get finishing time for W parsing\n",
    "        pw2 = time.time() \n",
    "        # display run times for W parsing \n",
    "        print(f\"Parsed Ws in {round((pw2-pw1), 3)} sec ({round((pw2-pw1)/len(list(self.Wsoup.items())), 5)} sec/ea.)\")\n",
    "        logging.info(f\"Parsed Ws in {round((pw2-pw1), 3)} sec ({round((pw2-pw1)/len(list(self.Wsoup.items())), 5)} sec/ea.)\")\n",
    "        logging.info(f\"Done parsing As and Ws\")\n",
    "        \n",
    "        logging.info(f\"Making dataframes\")\n",
    "        print(f\"Making AsDf\")\n",
    "        # create DataFrame of Agent dictionaries\n",
    "        AsDf = pd.DataFrame.from_dict(self.As, orient='index')\n",
    "        print(f\"Making WsDf\")\n",
    "        # create DataFrame of Work dictionaries\n",
    "        WsDf = pd.DataFrame.from_dict(self.Ws, orient='index')  \n",
    "        logging.info(f\"Done making dataframes\")\n",
    "        \n",
    "        logging.info(f\"Writing to json\")\n",
    "        # write Work DataFrame to JSON\n",
    "        WsDf.to_json('WsDf.json')\n",
    "        # write Agent DataFrame to JSON\n",
    "        AsDf.to_json('AsDf.json')\n",
    "        logging.info(f\"Done writing to json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_status(urls): \n",
    "    aberrantURLs = []\n",
    "    logging.info(f\"Checking status of URLs\")\n",
    "    for url in urls: \n",
    "        logging.info(f\"Trying {url}\")\n",
    "        with requests.get(url, verify=False) as r: \n",
    "            if r.status_code == 200: \n",
    "                #logging.info(f\"{url} successful\")\n",
    "                pass\n",
    "            else: \n",
    "                logging.info(f\"{url}: {r.status_code}\")\n",
    "                aberrantURLs.append({url: r.status_code})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__': \n",
    "    maprr().run()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "class MAPRR: \n",
    "    \n",
    "    def __init__(self): \n",
    "        self.urls_to_visit = []\n",
    "        self.aberrantAs = []\n",
    "        self.aberrantWs = []\n",
    "        self.soups = {}\n",
    "        self.Wsoup = {} \n",
    "        self.Asoup = {}\n",
    "        self.Ws = {}\n",
    "        self.As = {}\n",
    "    \n",
    "    def get_html(self, url): \n",
    "        url_format = 'https://mpgrr.herokuapp.com/(\\w+)/(\\d{1,3})'\n",
    "        url_match = re.match(url_format, url)\n",
    "        fco_type = url_match.group(1)\n",
    "        id_num = url_match.group(2)\n",
    "        headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36',\n",
    "    }\n",
    "        with requests.get(url, headers=headers) as r: \n",
    "            logging.info(f\"{fco_type}/{id_num} status code: {r.status_code}\")\n",
    "            if r.status_code == 200: \n",
    "                s = BeautifulSoup(r.content, 'html.parser')\n",
    "                #self.soups.update({id_num:s})\n",
    "                if fco_type == 'agents': \n",
    "                    self.Asoup.update({id_num:s})\n",
    "                elif fco_type == 'works': \n",
    "                    self.Wsoup.update({id_num:s})\n",
    "            else: \n",
    "                if fco_type == 'agents': \n",
    "                    self.aberrantAs.append({'A'+str(id_num): r.status_code})\n",
    "                elif fco_type == 'works': \n",
    "                    self.aberrantWs.append({'W'+str(id_num): r.status_code})\n",
    "                pass\n",
    "        time.sleep(.5)\n",
    "        \n",
    "    def parse_html(self, html): \n",
    "        if 'works' in list(html.body.attrs.values())[0]: \n",
    "            content = html.find('div', {'class':'col-md-9 fixed-height'})\n",
    "            try: \n",
    "                author = content.div.h3.text\n",
    "            except: \n",
    "                author = \"\"\n",
    "            try: \n",
    "                title = content.div.h4.text\n",
    "            except: \n",
    "                title = \"\"\n",
    "            stanza_text = content.find_all('p',{'class':'stanza'})\n",
    "            prose_text = content.find_all('p',{'class':'text'})\n",
    "            if len(stanza_text) > len(prose_text): \n",
    "                text = stanza_text\n",
    "            elif len(stanza_text) < len(prose_text): \n",
    "                text = prose_text\n",
    "            Wtext = [x.text.replace('\\n','').strip() for x in text]\n",
    "            metaKeys = [x.text[:-1] for x in html.find('div', {'class':'card-body'}).find_all('h4')]\n",
    "            metaVals = [x.text for x in html.find('div', {'class':'card-body'}).find_all('p')]\n",
    "            metaDict = dict(zip(metaKeys, metaVals))\n",
    "            subDict = {'title': title, \n",
    "                       'text': Wtext}\n",
    "\n",
    "            #self.Ws.update(subdict)\n",
    "            return subDict\n",
    "\n",
    "        elif 'agents' in list(html.body.attrs.values())[0]: \n",
    "            name = html.find('div', {'class': 'card scrollable'}).h2.text\n",
    "            bdate, ddate = html.find('div', {'class': 'card scrollable'}).span.text.split(' - ')\n",
    "            subDict = {'name': name, 'birth': bdate, 'death': ddate}\n",
    "            try: \n",
    "                typeKeys = [x.h4.text for x in html.find_all('div', {'class': 'col-md-4'})]\n",
    "                typeVals = [x.p or x.div.span.text for x in html.find_all('div', {'class': 'col-md-4'})]\n",
    "                typeVals[:2] = [x.text for x in typeVals[:2]]\n",
    "                typeDict = dict(zip(typeKeys, typeVals))\n",
    "                subDict.update(typeDict)\n",
    "            except: \n",
    "                pass\n",
    "\n",
    "            #self.As.update(subdict)\n",
    "            return subDict\n",
    "\n",
    "    def run(self): \n",
    "        for t, i in list(tables.items())[:2]: \n",
    "            for j in range(0,5): \n",
    "                self.urls_to_visit.append(domain+t+str(j))\n",
    "        \n",
    "        logging.info(f\"Getting As and Ws\")\n",
    "        for url in self.urls_to_visit: \n",
    "            self.get_html(url) \n",
    "        logging.info(f\"Done getting As and Ws\")\n",
    "        \n",
    "        logging.info(f\"Parsing As and Ws\")\n",
    "        print(f\"Parsing As\")\n",
    "        self.As = {k: self.parse_html(v) for k, v in self.Asoup.items()}\n",
    "        print(f\"Parsing Ws\")\n",
    "        self.Ws = {k: self.parse_html(v) for k, v in self.Wsoup.items()}        \n",
    "        logging.info(f\"Done parsing As and Ws\")\n",
    "        \n",
    "        logging.info(f\"Making dataframes\")\n",
    "        print(f\"Making AsDf\")\n",
    "        AsDf = pd.DataFrame.from_dict(self.As, orient='index')\n",
    "        print(f\"Making WsDf\")\n",
    "        WsDf = pd.DataFrame.from_dict(self.Ws, orient='index')        \n",
    "        logging.info(f\"Done making dataframes\")\n",
    "        \n",
    "        logging.info(f\"Writing to json\")\n",
    "        WsDf.to_json('WsDf.json')\n",
    "        AsDf.to_json('AsDf.json')\n",
    "        logging.info(f\"Done writing to json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ParallelMAPRR: \n",
    "    \n",
    "    global domain, tables, max_threads\n",
    "    \n",
    "    def __init__(self): \n",
    "        self.urls_to_visit = []\n",
    "        self.aberrantAs = []\n",
    "        self.aberrantWs = []\n",
    "        self.soups = {}\n",
    "        self.Wsoup = {} \n",
    "        self.Asoup = {}\n",
    "        self.WsDict = {}\n",
    "        self.AsDict = {}\n",
    "    \n",
    "    def get_html(self, url): \n",
    "        url_format = 'https://maprr.iath.virginia.edu/(\\w+)/(\\d{1,3})'\n",
    "        url_match = re.match(url_format, url)\n",
    "        fco_type = url_match.group(1)\n",
    "        id_num = url_match.group(2)\n",
    "        headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36',\n",
    "    }\n",
    "        with requests.get(url, headers=headers) as r: \n",
    "            logging.info(f\"{fco_type}/{id_num} status code: {r.status_code}\")\n",
    "            if r.status_code == 200: \n",
    "                s = BeautifulSoup(r.content, 'html.parser')\n",
    "                self.soups.update({id_num:s})\n",
    "                if fco_type == 'agents': \n",
    "                    self.Asoup.update({id_num:s})\n",
    "                elif fco_type == 'works': \n",
    "                    self.Wsoup.update({id_num:s})\n",
    "            else: \n",
    "                if fco_type == 'agents': \n",
    "                    self.aberrantAs.append({'A'+str(id_num): r.status_code})\n",
    "                elif fco_type == 'works': \n",
    "                    self.aberrantWs.append({'W'+str(id_num): r.status_code})\n",
    "                pass\n",
    "        time.sleep(.5)\n",
    "            \n",
    "    def downloadHTML(self): \n",
    "        threads = min(max_threads, len(self.urls_to_visit)) \n",
    "        print(f\"Downloading with {threads} threads\")\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=threads) as executor: \n",
    "            executor.map(self.get_html, self.urls_to_visit)\n",
    "\n",
    "    def parse_html(self, html): \n",
    "        _attrs = list(html.body.attrs.values())[0]\n",
    "        logging.info(f\"html body attrs: {_attrs}\")\n",
    "        \n",
    "        if 'works' in _attrs:\n",
    "            logging.info(\"parsing W\")\n",
    "            content = html.find('div', {'class':'col-md-9 fixed-height'})\n",
    "            try: \n",
    "                author = content.div.h3.text\n",
    "            except: \n",
    "                author = \"\"\n",
    "            logging.info(f\"author: {author}\")\n",
    "            try: \n",
    "                title = content.div.h4.text\n",
    "            except: \n",
    "                title = \"\"\n",
    "            logging.info(f\"title: {title}\")\n",
    "            stanza_text = content.find_all('p',{'class':'stanza'})\n",
    "            prose_text = content.find_all('p',{'class':'text'})\n",
    "            if len(stanza_text) > len(prose_text): \n",
    "                text = stanza_text\n",
    "            elif len(stanza_text) < len(prose_text): \n",
    "                text = prose_text\n",
    "            Wtext = [x.text.replace('\\n','').strip() for x in text]\n",
    "            metaKeys = [x.text[:-1] for x in html.find('div', {'class':'card-body'}).find_all('h4')]\n",
    "            metaVals = [x.text for x in html.find('div', {'class':'card-body'}).find_all('p')]\n",
    "            metaDict = dict(zip(metaKeys, metaVals))\n",
    "            subDict = {'title': title, \n",
    "                       'text': Wtext}\n",
    "            subDict.update(metaDict)\n",
    "            logging.info(f\"W subdict: {subDict}\")\n",
    "            self.WsDict.update(subDict)\n",
    "            #return subDict\n",
    "\n",
    "        elif 'agents' in _attrs: \n",
    "            logging.info(\"parsing A\")\n",
    "            name = html.find('div', {'class': 'card scrollable'}).h2.text\n",
    "            bdate, ddate = html.find('div', {'class': 'card scrollable'}).span.text.split(' - ')\n",
    "            subDict = {'name': name, 'birth': bdate, 'death': ddate}\n",
    "            try: \n",
    "                typeKeys = [x.h4.text for x in html.find_all('div', {'class': 'col-md-4'})]\n",
    "                typeVals = [x.p or x.div.span.text for x in html.find_all('div', {'class': 'col-md-4'})]\n",
    "                typeVals[:2] = [x.text for x in typeVals[:2]]\n",
    "                typeDict = dict(zip(typeKeys, typeVals))\n",
    "                subDict.update(typeDict)\n",
    "            except: \n",
    "                pass\n",
    "\n",
    "            logging.info(f\"A subdict: {subDict}\")\n",
    "            self.AsDict.update(subDict)\n",
    "            #return subDict\n",
    "        \n",
    "        else: \n",
    "            logging.info(f\"Something went wrong while parsing\")\n",
    "            pass\n",
    "    \n",
    "    def parseHTML(self): \n",
    "        threads = min(max_threads, len(self.urls_to_visit)) \n",
    "        logging.info(f\"Parsing with {threads} threads\")\n",
    "        with concurrent.futures.ProcessPoolExecutor(max_workers=threads) as executor: \n",
    "            executor.map(self.parse_html, list(self.soups.values()))\n",
    "        \n",
    "    def run(self): \n",
    "        for t, i in list(tables.items())[:2]: \n",
    "            for j in range(1,5): \n",
    "                self.urls_to_visit.append(domain+t+str(j))\n",
    "                \n",
    "        #logging.info(f\"urls: {self.urls_to_visit}\")\n",
    "        \n",
    "        logging.info(f\"Getting As and Ws\")\n",
    "        self.downloadHTML()\n",
    "        logging.info(f\"Done getting As and Ws\")\n",
    "\n",
    "        logging.info(f\"soups: {list(self.soups.values())}\")\n",
    "        #logging.info(f\"Wsoup: {self.Wsoup}\")\n",
    "        logging.info(f\"Abberrant Ws: {self.aberrantWs}\")\n",
    "        logging.info(f\"Abberrant As: {self.aberrantAs}\")\n",
    "        \n",
    "        logging.info(f\"Parsing As and Ws\")\n",
    "        self.parseHTML()\n",
    "        logging.info(f\"Done parsing As and Ws\")\n",
    "\n",
    "        #logging.info(f\"Making AsDf\")\n",
    "        logging.info(f\"As: {self.AsDict}\")\n",
    "        #AsDf = pd.DataFrame.from_dict(self.AsDict)\n",
    "        #logging.info(f\"Making WsDf\")\n",
    "        logging.info(f\"Ws: {self.WsDict}\")\n",
    "        #WsDf = pd.DataFrame.from_dict(self.WsDict)        \n",
    "        #logging.info(f\"Done making dataframes\")\n",
    "        \n",
    "        #logging.info(f\"Writing to json\")\n",
    "        #WsDf.to_json('WsDf.json')\n",
    "        #AsDf.to_json('AsDf.json')\n",
    "        #logging.info(f\"Done writing to json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading with 3 threads\n",
      "CPU times: user 455 ms, sys: 66.4 ms, total: 522 ms\n",
      "Wall time: 2.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == '__main__': \n",
    "    ParallelMAPRR().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = []\n",
    "\n",
    "with (open('/home/xtra/code/maprr/Wsoup.pkl', \"rb\")) as f:\n",
    "    objects.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"works\" in list(list(objects[0].values())[0].html.body.attrs.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(list(objects[0].values())[0].html.body.attrs.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(objects[0].values())[0].html.body.find('div', {'class':'col-md-9 fixed-height'})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\" = AsDf.append(maprr().get_single(cat='agent', id_num=45))\n",
    "\n",
    "AsDf['birth'] = pd.to_datetime(AsDf['birth'], errors='coerce', infer_datetime_format=True)\n",
    "AsDf['death'] = pd.to_datetime(AsDf['death'], errors='coerce', infer_datetime_format=True)\n",
    "AsDf.sort_index()#[AsDf.name.str.contains('Osip')]\n",
    "AsDf.to_json('AsDf.json')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>birth</th>\n",
       "      <th>death</th>\n",
       "      <th>Type of Agent</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Occupations</th>\n",
       "      <th>Family Social Strata</th>\n",
       "      <th>Literary Affiliations</th>\n",
       "      <th>Political Affiliations</th>\n",
       "      <th>Type of Corporate Body</th>\n",
       "      <th>Affiliation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Anna Akhmatova</td>\n",
       "      <td>1889-06-23</td>\n",
       "      <td>1966-03-05</td>\n",
       "      <td>person</td>\n",
       "      <td>female</td>\n",
       "      <td>poet</td>\n",
       "      <td>nobility</td>\n",
       "      <td>Acmeism</td>\n",
       "      <td>independent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Vasilii Dmitrievich Aleksandrovskii</td>\n",
       "      <td>1897-01-15</td>\n",
       "      <td>1934-11-16</td>\n",
       "      <td>person</td>\n",
       "      <td>male</td>\n",
       "      <td>soldier</td>\n",
       "      <td>peasant</td>\n",
       "      <td>Kuznitsa</td>\n",
       "      <td>Bolshevik member</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Ivan Nikolaevich Antonov</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>person</td>\n",
       "      <td>male</td>\n",
       "      <td>editor</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>independent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mikhail Dmitrievich Artamonov</td>\n",
       "      <td>1888-02-22</td>\n",
       "      <td>1958-11-22</td>\n",
       "      <td>person</td>\n",
       "      <td>male</td>\n",
       "      <td>journalist</td>\n",
       "      <td>peasant</td>\n",
       "      <td>Vologda poets</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Nikolai Aseev</td>\n",
       "      <td>1889-07-10</td>\n",
       "      <td>1963-07-16</td>\n",
       "      <td>person</td>\n",
       "      <td>male</td>\n",
       "      <td>soldier</td>\n",
       "      <td>nobility</td>\n",
       "      <td>Left Front of Art: LEF</td>\n",
       "      <td>Bolshevik member</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>300</td>\n",
       "      <td>Moisei Solomonovich Uritskii</td>\n",
       "      <td>1873-01-14</td>\n",
       "      <td>1918-08-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>301</td>\n",
       "      <td>Maximilien Marie Isidore de Robespierre</td>\n",
       "      <td>1758-05-06</td>\n",
       "      <td>1794-06-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>302</td>\n",
       "      <td>Iurii Mikhailovich Steklov</td>\n",
       "      <td>1873-08-27</td>\n",
       "      <td>1941-07-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>303</td>\n",
       "      <td>Christian August Friedrich Peters</td>\n",
       "      <td>1806-09-07</td>\n",
       "      <td>1880-05-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>304</td>\n",
       "      <td>Émile Adolphe Gustave Verhaeren</td>\n",
       "      <td>1855-05-21</td>\n",
       "      <td>1916-11-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>290 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                     name      birth  \\\n",
       "0             1                           Anna Akhmatova 1889-06-23   \n",
       "1             2      Vasilii Dmitrievich Aleksandrovskii 1897-01-15   \n",
       "2             3                 Ivan Nikolaevich Antonov        NaT   \n",
       "3             4            Mikhail Dmitrievich Artamonov 1888-02-22   \n",
       "4             5                            Nikolai Aseev 1889-07-10   \n",
       "..          ...                                      ...        ...   \n",
       "285         300             Moisei Solomonovich Uritskii 1873-01-14   \n",
       "286         301  Maximilien Marie Isidore de Robespierre 1758-05-06   \n",
       "287         302               Iurii Mikhailovich Steklov 1873-08-27   \n",
       "288         303        Christian August Friedrich Peters 1806-09-07   \n",
       "289         304          Émile Adolphe Gustave Verhaeren 1855-05-21   \n",
       "\n",
       "         death Type of Agent     Sex Occupations Family Social Strata  \\\n",
       "0   1966-03-05        person  female        poet             nobility   \n",
       "1   1934-11-16        person    male     soldier              peasant   \n",
       "2          NaT        person    male      editor              unknown   \n",
       "3   1958-11-22        person    male  journalist              peasant   \n",
       "4   1963-07-16        person    male     soldier             nobility   \n",
       "..         ...           ...     ...         ...                  ...   \n",
       "285 1918-08-30           NaN     NaN         NaN                  NaN   \n",
       "286 1794-06-28           NaN     NaN         NaN                  NaN   \n",
       "287 1941-07-15           NaN     NaN         NaN                  NaN   \n",
       "288 1880-05-08           NaN     NaN         NaN                  NaN   \n",
       "289 1916-11-27           NaN     NaN         NaN                  NaN   \n",
       "\n",
       "      Literary Affiliations Political Affiliations Type of Corporate Body  \\\n",
       "0                   Acmeism            independent                    NaN   \n",
       "1                  Kuznitsa       Bolshevik member                    NaN   \n",
       "2                   unknown            independent                    NaN   \n",
       "3             Vologda poets                unknown                    NaN   \n",
       "4    Left Front of Art: LEF       Bolshevik member                    NaN   \n",
       "..                      ...                    ...                    ...   \n",
       "285                     NaN                    NaN                    NaN   \n",
       "286                     NaN                    NaN                    NaN   \n",
       "287                     NaN                    NaN                    NaN   \n",
       "288                     NaN                    NaN                    NaN   \n",
       "289                     NaN                    NaN                    NaN   \n",
       "\n",
       "    Affiliation  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  \n",
       "..          ...  \n",
       "285         NaN  \n",
       "286         NaN  \n",
       "287         NaN  \n",
       "288         NaN  \n",
       "289         NaN  \n",
       "\n",
       "[290 rows x 12 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AsDf = pd.read_csv('AsDf.csv')\n",
    "AsDf['birth'] = pd.to_datetime(AsDf['birth'], errors='coerce', infer_datetime_format=True)\n",
    "AsDf['death'] = pd.to_datetime(AsDf['death'], errors='coerce', infer_datetime_format=True)\n",
    "AsDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### libDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(586, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w_id</th>\n",
       "      <th>title_ru</th>\n",
       "      <th>text</th>\n",
       "      <th>title_en</th>\n",
       "      <th>1st_line</th>\n",
       "      <th>author</th>\n",
       "      <th>comp_date</th>\n",
       "      <th>comp_loc</th>\n",
       "      <th>pub_src</th>\n",
       "      <th>1st_pub</th>\n",
       "      <th>pub_year</th>\n",
       "      <th>pub_loc</th>\n",
       "      <th>num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Untitled</td>\n",
       "      <td>['Сразу стало тихо в доме,                Обле...</td>\n",
       "      <td>no title</td>\n",
       "      <td>Srazu stalo tikho v dome…</td>\n",
       "      <td>Anna Akhmatova</td>\n",
       "      <td>1917-07-01</td>\n",
       "      <td>Slepnevo</td>\n",
       "      <td>Podorozhnik</td>\n",
       "      <td>Petropolis</td>\n",
       "      <td>1921.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Untitled</td>\n",
       "      <td>['Ты — отступник: за остров зелёный           ...</td>\n",
       "      <td>no title</td>\n",
       "      <td>Ty - otstupnik: za ostrov zelenyi…</td>\n",
       "      <td>Anna Akhmatova</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Slepnevo</td>\n",
       "      <td>Podorozhnik</td>\n",
       "      <td>Petropolis</td>\n",
       "      <td>1921.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Untitled</td>\n",
       "      <td>['Просыпаться на рассвете                Оттог...</td>\n",
       "      <td>no title</td>\n",
       "      <td>Prosypat'sia na rassvete…</td>\n",
       "      <td>Anna Akhmatova</td>\n",
       "      <td>1917-07-01</td>\n",
       "      <td>Slepnevo</td>\n",
       "      <td>Podorozhnik</td>\n",
       "      <td>Petropolis</td>\n",
       "      <td>1921.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Untitled</td>\n",
       "      <td>['И в тайную дружбу с высоким,                ...</td>\n",
       "      <td>no title</td>\n",
       "      <td>I v tainuiu druzhbu c vysokim…</td>\n",
       "      <td>Anna Akhmatova</td>\n",
       "      <td>1917-01-01</td>\n",
       "      <td>Petrograd</td>\n",
       "      <td>Podorozhnik</td>\n",
       "      <td>Petropolis</td>\n",
       "      <td>1921.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Untitled</td>\n",
       "      <td>['Словно ангел, возмутивший воду,             ...</td>\n",
       "      <td>no title</td>\n",
       "      <td>Slovno angel, vozmutivshii vodu…</td>\n",
       "      <td>Anna Akhmatova</td>\n",
       "      <td>1916-02-01</td>\n",
       "      <td>Tsarskoe selo</td>\n",
       "      <td>Podorozhnik</td>\n",
       "      <td>Petropolis</td>\n",
       "      <td>1921.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>599</td>\n",
       "      <td>Untitled</td>\n",
       "      <td>['Любовь распяли на кресте,               Но в...</td>\n",
       "      <td>\"Liubov' raspiali na kreste\"</td>\n",
       "      <td>Liubov' raspiali na kreste</td>\n",
       "      <td>Georgii Andreevich Viatkin</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Omsk</td>\n",
       "      <td>Ranenaia Rossiia: Stikhi; Vernost': rasskaz; E...</td>\n",
       "      <td>Tipografiia Vremennogo Tsentral’nogo Voenno-P...</td>\n",
       "      <td>1919.0</td>\n",
       "      <td>Ekaterinburg</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>600</td>\n",
       "      <td>На словах...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Na slovakh... (Nesvoevremennye mysli)</td>\n",
       "      <td>Na slovakh--vse soglasny...</td>\n",
       "      <td>Maksim Gor'kii</td>\n",
       "      <td>1917-06-29</td>\n",
       "      <td>Petrograd</td>\n",
       "      <td>Novaia zhizn'</td>\n",
       "      <td>A. N. Tikhonov</td>\n",
       "      <td>1917.0</td>\n",
       "      <td>Petrograd</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>601</td>\n",
       "      <td>Последняя просьба</td>\n",
       "      <td>['Сестра!.. Сестрица, на минутку подойдите    ...</td>\n",
       "      <td>Posledniaia pros'ba</td>\n",
       "      <td>Sestra! Sestritsa, na minutku podoidite…</td>\n",
       "      <td>M Kolchin</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pesni voiny: posviashchaetsia doblestnym sibir...</td>\n",
       "      <td>Tipografiia I. M. Poznera</td>\n",
       "      <td>1915.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>602</td>\n",
       "      <td>И рек Сидящий на престоле</td>\n",
       "      <td>['В борьбе с врагом, в борьбе кровавой, геройс...</td>\n",
       "      <td>I rek Sidiashchii na prestole</td>\n",
       "      <td>V bor'be s vragom, v bor'be krovavom...</td>\n",
       "      <td>M. Did</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nabat: Stikhotvoreniia, 1914-1915</td>\n",
       "      <td>Tipografiia N. A. Vorob'eva</td>\n",
       "      <td>1916.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>603</td>\n",
       "      <td>«Двенадцать»</td>\n",
       "      <td>['Черный ветер.                  Белый снег.  ...</td>\n",
       "      <td>Dvenadtsat'</td>\n",
       "      <td>Chernyi veter.</td>\n",
       "      <td>Aleksandr Aleksandrovich Blok</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Znamia truda</td>\n",
       "      <td>Znamia truda</td>\n",
       "      <td>1918.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>586 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     w_id                   title_ru  \\\n",
       "0       1                   Untitled   \n",
       "1       2                   Untitled   \n",
       "2       3                   Untitled   \n",
       "3       4                   Untitled   \n",
       "4       5                   Untitled   \n",
       "..    ...                        ...   \n",
       "581   599                   Untitled   \n",
       "582   600              На словах...    \n",
       "583   601          Последняя просьба   \n",
       "584   602  И рек Сидящий на престоле   \n",
       "585   603               «Двенадцать»   \n",
       "\n",
       "                                                  text  \\\n",
       "0    ['Сразу стало тихо в доме,                Обле...   \n",
       "1    ['Ты — отступник: за остров зелёный           ...   \n",
       "2    ['Просыпаться на рассвете                Оттог...   \n",
       "3    ['И в тайную дружбу с высоким,                ...   \n",
       "4    ['Словно ангел, возмутивший воду,             ...   \n",
       "..                                                 ...   \n",
       "581  ['Любовь распяли на кресте,               Но в...   \n",
       "582                                                 []   \n",
       "583  ['Сестра!.. Сестрица, на минутку подойдите    ...   \n",
       "584  ['В борьбе с врагом, в борьбе кровавой, геройс...   \n",
       "585  ['Черный ветер.                  Белый снег.  ...   \n",
       "\n",
       "                                  title_en  \\\n",
       "0                                 no title   \n",
       "1                                 no title   \n",
       "2                                 no title   \n",
       "3                                 no title   \n",
       "4                                 no title   \n",
       "..                                     ...   \n",
       "581           \"Liubov' raspiali na kreste\"   \n",
       "582  Na slovakh... (Nesvoevremennye mysli)   \n",
       "583                    Posledniaia pros'ba   \n",
       "584          I rek Sidiashchii na prestole   \n",
       "585                            Dvenadtsat'   \n",
       "\n",
       "                                     1st_line                         author  \\\n",
       "0                   Srazu stalo tikho v dome…                 Anna Akhmatova   \n",
       "1          Ty - otstupnik: za ostrov zelenyi…                 Anna Akhmatova   \n",
       "2                   Prosypat'sia na rassvete…                 Anna Akhmatova   \n",
       "3              I v tainuiu druzhbu c vysokim…                 Anna Akhmatova   \n",
       "4            Slovno angel, vozmutivshii vodu…                 Anna Akhmatova   \n",
       "..                                        ...                            ...   \n",
       "581                Liubov' raspiali na kreste     Georgii Andreevich Viatkin   \n",
       "582               Na slovakh--vse soglasny...                 Maksim Gor'kii   \n",
       "583  Sestra! Sestritsa, na minutku podoidite…                      M Kolchin   \n",
       "584   V bor'be s vragom, v bor'be krovavom...                         M. Did   \n",
       "585                            Chernyi veter.  Aleksandr Aleksandrovich Blok   \n",
       "\n",
       "     comp_date       comp_loc  \\\n",
       "0   1917-07-01       Slepnevo   \n",
       "1          NaT       Slepnevo   \n",
       "2   1917-07-01       Slepnevo   \n",
       "3   1917-01-01      Petrograd   \n",
       "4   1916-02-01  Tsarskoe selo   \n",
       "..         ...            ...   \n",
       "581        NaT           Omsk   \n",
       "582 1917-06-29      Petrograd   \n",
       "583        NaT            NaN   \n",
       "584        NaT            NaN   \n",
       "585        NaT            NaN   \n",
       "\n",
       "                                               pub_src  \\\n",
       "0                                          Podorozhnik   \n",
       "1                                          Podorozhnik   \n",
       "2                                          Podorozhnik   \n",
       "3                                          Podorozhnik   \n",
       "4                                          Podorozhnik   \n",
       "..                                                 ...   \n",
       "581  Ranenaia Rossiia: Stikhi; Vernost': rasskaz; E...   \n",
       "582                                      Novaia zhizn'   \n",
       "583  Pesni voiny: posviashchaetsia doblestnym sibir...   \n",
       "584                  Nabat: Stikhotvoreniia, 1914-1915   \n",
       "585                                       Znamia truda   \n",
       "\n",
       "                                               1st_pub  pub_year  \\\n",
       "0                                           Petropolis    1921.0   \n",
       "1                                           Petropolis    1921.0   \n",
       "2                                           Petropolis    1921.0   \n",
       "3                                           Petropolis    1921.0   \n",
       "4                                           Petropolis    1921.0   \n",
       "..                                                 ...       ...   \n",
       "581   Tipografiia Vremennogo Tsentral’nogo Voenno-P...    1919.0   \n",
       "582                                     A. N. Tikhonov    1917.0   \n",
       "583                          Tipografiia I. M. Poznera    1915.0   \n",
       "584                        Tipografiia N. A. Vorob'eva    1916.0   \n",
       "585                                      Znamia truda     1918.0   \n",
       "\n",
       "          pub_loc  num_words  \n",
       "0             NaN        432  \n",
       "1             NaN        815  \n",
       "2             NaN        470  \n",
       "3             NaN        284  \n",
       "4             NaN        336  \n",
       "..            ...        ...  \n",
       "581  Ekaterinburg        457  \n",
       "582     Petrograd          2  \n",
       "583           NaN        824  \n",
       "584           NaN       1624  \n",
       "585           NaN      13210  \n",
       "\n",
       "[586 rows x 13 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "libDf = pd.read_csv('WsDf.csv')\n",
    "#libDf.index.name = 'w_id'\n",
    "libDf.columns = lib_cols\n",
    "libDf['comp_date'] = pd.to_datetime(libDf['comp_date'], errors='coerce')\n",
    "libDf['pub_year'] = pd.to_datetime(libDf['pub_year'], errors='coerce')\n",
    "libDf['pub_year'] = libDf.pub_year.apply(lambda x: x.year).astype('int64', errors='ignore')\n",
    "libDf['num_words'] = libDf.text.str.len()\n",
    "print(libDf.shape)\n",
    "#type(libDf.loc[1, 'pub_year'])\n",
    "libDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### authorsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>birth</th>\n",
       "      <th>death</th>\n",
       "      <th>Type of Agent</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Occupations</th>\n",
       "      <th>Family Social Strata</th>\n",
       "      <th>Literary Affiliations</th>\n",
       "      <th>Political Affiliations</th>\n",
       "      <th>Type of Corporate Body</th>\n",
       "      <th>Affiliation</th>\n",
       "      <th>index_y</th>\n",
       "      <th>num_works</th>\n",
       "      <th>num_words</th>\n",
       "      <th>avg_wpw</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63.0</th>\n",
       "      <td>65.0</td>\n",
       "      <td>S. D. Spasskii</td>\n",
       "      <td>1898-12-21</td>\n",
       "      <td>1956-08-24</td>\n",
       "      <td>person</td>\n",
       "      <td>male</td>\n",
       "      <td>writer</td>\n",
       "      <td>professional</td>\n",
       "      <td>Futurism</td>\n",
       "      <td>independent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>10654</td>\n",
       "      <td>10654.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23.0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Evsei Davydovich Erkin</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1942-12-06</td>\n",
       "      <td>person</td>\n",
       "      <td>male</td>\n",
       "      <td>writer</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Pereval</td>\n",
       "      <td>Bolshevik member</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>10471</td>\n",
       "      <td>10471.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Aleksandr Il'ich Bezymenskii</td>\n",
       "      <td>1898-01-19</td>\n",
       "      <td>1973-06-06</td>\n",
       "      <td>person</td>\n",
       "      <td>male</td>\n",
       "      <td>poet</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Kuznitsa</td>\n",
       "      <td>Komsomol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>21643</td>\n",
       "      <td>5410.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>Fëdor Semënovich Bogorodskii</td>\n",
       "      <td>1895-06-02</td>\n",
       "      <td>1959-11-03</td>\n",
       "      <td>person</td>\n",
       "      <td>male</td>\n",
       "      <td>painter</td>\n",
       "      <td>professional</td>\n",
       "      <td>Futurism</td>\n",
       "      <td>Bolshevik member</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>24528</td>\n",
       "      <td>4905.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>Aleksandr Aleksandrovich Blok</td>\n",
       "      <td>1880-11-28</td>\n",
       "      <td>1921-08-07</td>\n",
       "      <td>person</td>\n",
       "      <td>male</td>\n",
       "      <td>poet</td>\n",
       "      <td>nobility</td>\n",
       "      <td>Symbolism</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>18077</td>\n",
       "      <td>4519.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>17.0</td>\n",
       "      <td>Evgenii Nikolaevich Chirikov</td>\n",
       "      <td>1864-08-05</td>\n",
       "      <td>1932-01-18</td>\n",
       "      <td>person</td>\n",
       "      <td>male</td>\n",
       "      <td>writer</td>\n",
       "      <td>nobility</td>\n",
       "      <td>Gor'kii circle</td>\n",
       "      <td>Populist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61.0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>Viacheslav Iakovlevich Shishkov</td>\n",
       "      <td>1873-10-03</td>\n",
       "      <td>1945-03-06</td>\n",
       "      <td>person</td>\n",
       "      <td>male</td>\n",
       "      <td>explorer</td>\n",
       "      <td>merchant</td>\n",
       "      <td>unknown</td>\n",
       "      <td>nationalist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>16.0</td>\n",
       "      <td>Aleksandr Vasil'evich Chaianov</td>\n",
       "      <td>1888-01-29</td>\n",
       "      <td>1937-10-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>Arkadii Timofeevich Averchenko</td>\n",
       "      <td>1880-03-27</td>\n",
       "      <td>1925-03-12</td>\n",
       "      <td>person</td>\n",
       "      <td>male</td>\n",
       "      <td>satirist</td>\n",
       "      <td>merchant</td>\n",
       "      <td>New Satirikon circle</td>\n",
       "      <td>nationalist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39.0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>Aleksandra Kollontai</td>\n",
       "      <td>1872-03-31</td>\n",
       "      <td>1952-03-09</td>\n",
       "      <td>person</td>\n",
       "      <td>female</td>\n",
       "      <td>activist</td>\n",
       "      <td>nobility</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Menshevik</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                             name      birth      death  \\\n",
       "a_id                                                                      \n",
       "63.0        65.0                   S. D. Spasskii 1898-12-21 1956-08-24   \n",
       "23.0        24.0           Evsei Davydovich Erkin        NaT 1942-12-06   \n",
       "9.0         10.0     Aleksandr Il'ich Bezymenskii 1898-01-19 1973-06-06   \n",
       "11.0        12.0     Fëdor Semënovich Bogorodskii 1895-06-02 1959-11-03   \n",
       "10.0        11.0    Aleksandr Aleksandrovich Blok 1880-11-28 1921-08-07   \n",
       "...          ...                              ...        ...        ...   \n",
       "16.0        17.0     Evgenii Nikolaevich Chirikov 1864-08-05 1932-01-18   \n",
       "61.0        63.0  Viacheslav Iakovlevich Shishkov 1873-10-03 1945-03-06   \n",
       "15.0        16.0   Aleksandr Vasil'evich Chaianov 1888-01-29 1937-10-03   \n",
       "5.0          6.0   Arkadii Timofeevich Averchenko 1880-03-27 1925-03-12   \n",
       "39.0        40.0             Aleksandra Kollontai 1872-03-31 1952-03-09   \n",
       "\n",
       "     Type of Agent     Sex Occupations Family Social Strata  \\\n",
       "a_id                                                          \n",
       "63.0        person    male      writer         professional   \n",
       "23.0        person    male      writer              unknown   \n",
       "9.0         person    male        poet              unknown   \n",
       "11.0        person    male     painter         professional   \n",
       "10.0        person    male        poet             nobility   \n",
       "...            ...     ...         ...                  ...   \n",
       "16.0        person    male      writer             nobility   \n",
       "61.0        person    male    explorer             merchant   \n",
       "15.0           NaN     NaN         NaN                  NaN   \n",
       "5.0         person    male    satirist             merchant   \n",
       "39.0        person  female    activist             nobility   \n",
       "\n",
       "     Literary Affiliations Political Affiliations Type of Corporate Body  \\\n",
       "a_id                                                                       \n",
       "63.0              Futurism            independent                    NaN   \n",
       "23.0               Pereval       Bolshevik member                    NaN   \n",
       "9.0               Kuznitsa               Komsomol                    NaN   \n",
       "11.0              Futurism       Bolshevik member                    NaN   \n",
       "10.0             Symbolism                unknown                    NaN   \n",
       "...                    ...                    ...                    ...   \n",
       "16.0        Gor'kii circle               Populist                    NaN   \n",
       "61.0               unknown            nationalist                    NaN   \n",
       "15.0                   NaN                    NaN                    NaN   \n",
       "5.0   New Satirikon circle            nationalist                    NaN   \n",
       "39.0               unknown              Menshevik                    NaN   \n",
       "\n",
       "     Affiliation  index_y  num_works  num_words   avg_wpw  \n",
       "a_id                                                       \n",
       "63.0         NaN       56          1      10654  10654.00  \n",
       "23.0         NaN       26          1      10471  10471.00  \n",
       "9.0          NaN        3          4      21643   5410.75  \n",
       "11.0         NaN       27          5      24528   4905.60  \n",
       "10.0         NaN        0          4      18077   4519.25  \n",
       "...          ...      ...        ...        ...       ...  \n",
       "16.0         NaN       25          4          8      2.00  \n",
       "61.0         NaN       68          2          4      2.00  \n",
       "15.0         NaN        8          1          2      2.00  \n",
       "5.0          NaN       17          9         18      2.00  \n",
       "39.0         NaN        9          1          2      2.00  \n",
       "\n",
       "[72 rows x 16 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authorsDf = libDf.reset_index().groupby('author').size().to_frame().rename(columns={0:'num_works'})\n",
    "authorsDf['num_words'] = libDf.reset_index().groupby('author').sum().num_words\n",
    "authorsDf['avg_wpw'] = round(authorsDf.num_words/authorsDf.num_works, 2)\n",
    "authorsDf = authorsDf.reset_index().sort_values(by=['avg_wpw'], ascending=False).rename(columns={'author':'name'})\n",
    "authorsDf = pd.merge(AsDf.reset_index(), authorsDf.reset_index(), how='right', on='name').set_index('index_x')\n",
    "authorsDf.index.name = 'a_id'\n",
    "authorsDf.to_json('authorsDf.json', date_format='iso')\n",
    "authorsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authorsDf = pd.read_json('authorsDf.json')\n",
    "#authorsDf[['birth', 'death']] = authorsDf[['birth', 'death']].apply(pd.to_datetime, format=\"%Y-%m-%d\")\n",
    "#[dt.to_datetime().date() for dt in authorsDf[['birth', 'death']]]\n",
    "authorsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(authorsDf.loc[15, 'death'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### worksDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xtra/.local/lib/python3.9/site-packages/pandas/core/frame.py:3602: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>['Посвящаю эту повесть двухлетнему Грише,     ...</td>\n",
       "      <td>7758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>['Каждым                  рявканьем пушечным  ...</td>\n",
       "      <td>7706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>['Защищал вход в Сербию, словно стая львов,   ...</td>\n",
       "      <td>5941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>['Черный ветер.                  Белый снег.  ...</td>\n",
       "      <td>5664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>['Как ветер с разбегу парус полощет,          ...</td>\n",
       "      <td>5467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>586 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  num_words\n",
       "108  ['Посвящаю эту повесть двухлетнему Грише,     ...       7758\n",
       "114  ['Каждым                  рявканьем пушечным  ...       7706\n",
       "134  ['Защищал вход в Сербию, словно стая львов,   ...       5941\n",
       "585  ['Черный ветер.                  Белый снег.  ...       5664\n",
       "430  ['Как ветер с разбегу парус полощет,          ...       5467\n",
       "..                                                 ...        ...\n",
       "61                                                  []          0\n",
       "221                                                 []          0\n",
       "220                                                 []          0\n",
       "219                                                 []          0\n",
       "64                                                  []          0\n",
       "\n",
       "[586 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textsDf = libDf[['text']]\n",
    "textsDf['num_words'] = libDf['num_words'] = textsDf.text.apply(lambda k: len([a for b in [x.split() for y in k for x in y.split('               ')] for a in b if a.isalpha() == True]))\n",
    "textsDf.sort_values('num_words', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['title', 'year', 'genre', 'num_lps'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [47]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m worksDf \u001b[38;5;241m=\u001b[39m \u001b[43mlibDf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtitle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauthor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgenre\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_lps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_words\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      2\u001b[0m worksDf\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/frame.py:3462\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3460\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3461\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3462\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3464\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/indexing.py:1311\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1309\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 1311\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_read_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m needs_i8_conversion(ax\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   1314\u001b[0m     ax, (IntervalIndex, CategoricalIndex)\n\u001b[1;32m   1315\u001b[0m ):\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;66;03m# For CategoricalIndex take instead of reindex to preserve dtype.\u001b[39;00m\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;66;03m#  For IntervalIndex this is to map integers to the Intervals they match to.\u001b[39;00m\n\u001b[1;32m   1318\u001b[0m     keyarr \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mtake(indexer)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/indexing.py:1374\u001b[0m, in \u001b[0;36m_LocIndexer._validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n\u001b[1;32m   1371\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1373\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 1374\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['title', 'year', 'genre', 'num_lps'] not in index\""
     ]
    }
   ],
   "source": [
    "worksDf = libDf[['title','year','author','genre','num_lps','num_words']]\n",
    "worksDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OHCO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [48]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m lpDf \u001b[38;5;241m=\u001b[39m libDf[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m      2\u001b[0m lpDf \u001b[38;5;241m=\u001b[39m lpDf\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: pd\u001b[38;5;241m.\u001b[39mSeries([y \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m x]))\u001b[38;5;241m.\u001b[39mstack()\u001b[38;5;241m.\u001b[39mto_frame()\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m0\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlp_str\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m----> 3\u001b[0m lpDf\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnames \u001b[38;5;241m=\u001b[39m \u001b[43mOHCO\u001b[49m[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m      4\u001b[0m lpDf\n\u001b[1;32m      5\u001b[0m tokenDf \u001b[38;5;241m=\u001b[39m lpDf\u001b[38;5;241m.\u001b[39mlp_str\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: tokenize(x))\u001b[38;5;241m.\u001b[39mto_frame()\u001b[38;5;66;03m#.rename(columns={0:'token'})\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'OHCO' is not defined"
     ]
    }
   ],
   "source": [
    "lpDf = libDf[['text']]\n",
    "lpDf = lpDf.text.apply(lambda x: pd.Series([y for y in x])).stack().to_frame().rename(columns={0:'lp_str'})\n",
    "lpDf.index.names = OHCO[:2]\n",
    "lpDf\n",
    "tokenDf = lpDf.lp_str.apply(lambda x: tokenize(x)).to_frame()#.rename(columns={0:'token'})\n",
    "#tokenDf = lpDf.lp_str.apply(lambda x: y.text for y in tokenize(x)[1])\n",
    "tokenDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tokenize(lpDf.lp_str): \n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "293d930ecca589385d8136ae0476c1fde7dc48a83b398052354be2f05bed9ba3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
